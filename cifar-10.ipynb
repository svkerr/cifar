{
 "metadata": {
  "name": "cifar-10"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**CIFAR-10 Archive:**\n",
      "Each of the batch files contains a dictionary with the following elements:\n",
      "\n",
      "data -- a 10000x3072 numpy array of uint8s. Each row of the array stores a 32x32 colour image. The first 1024 entries contain the red channel values, the next 1024 the green, and the final 1024 the blue. The image is stored in row-major order, so that the first 32 entries of the array are the red channel values of the first row of the image.\n",
      "labels -- a list of 10000 numbers in the range 0-9. The number at index i indicates the label of the ith image in the array data.\n",
      "\n",
      "The dataset contains another file, called batches.meta. It too contains a Python dictionary object. It has the following entries:\n",
      "\n",
      "label_names -- a 10-element list which gives meaningful names to the numeric labels in the labels array described above. For example, label_names[0] == \"airplane\", label_names[1] == \"automobile\", etc.\n",
      "\n",
      "The CIFAR-10 archive contains the files data_batch_1, data_batch_2, ..., data_batch_5, as well as test_batch. Each of these files is a Python \"pickled\" object produced with cPickle. Here is a Python routine which will open such a file and return a dictionary: "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sklearn as sk\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn.svm import SVC\n",
      "svc_1 = SVC(kernel='linear')\n",
      "rbf_svc = SVC(kernel='rbf')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The CIFAR-10 archive contains the files data_batch_1, data_batch_2, ..., data_batch_5, as well as test_batch. Each of these files is a Python \"pickled\" object produced with cPickle. Here is a Python routine which will open such a file and return a dictionary: "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def unpickle(file):\n",
      "    import cPickle\n",
      "    fo = open(file, 'rb')\n",
      "    dict = cPickle.load(fo)\n",
      "    fo.close()\n",
      "    return dict"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ls"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "batches.meta  cifar-10.ipynb  data_batch_1  data_batch_2  data_batch_3  data_batch_4  data_batch_5  readme.html  test_batch\r\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_batch_1 = unpickle('data_batch_1')\n",
      "train_batch_2 = unpickle('data_batch_2')\n",
      "train_batch_3 = unpickle('data_batch_3')\n",
      "train_batch_4 = unpickle('data_batch_4')\n",
      "train_batch_5 = unpickle('data_batch_5')\n",
      "test_batch_1 = unpickle('test_batch')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note that the data files have 3072 features. This is due to 32x32x3 (where three refers to RGB values for each pixel)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print train_batch_5['data'].shape\n",
      "print test_batch_1['data'].shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(10000, 3072)\n",
        "(10000, 3072)\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There are 10 classes of images. Let's see how well they are distributed by counting labels within a given training set:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import Counter\n",
      "label_counts = Counter(train_batch_1['labels'])\n",
      "print label_counts"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Counter({2: 1032, 6: 1030, 8: 1025, 3: 1016, 0: 1005, 7: 1001, 4: 999, 9: 981, 1: 974, 5: 937})\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To start off, let's use SciKitLearn's `train_test_split` on `train_batch_1` to create both train and test sets:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train,X_test, y_train, y_test = train_test_split(train_batch_1['data'], train_batch_1['labels'], test_size = 0.25, random_state=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Check some shapes and parameters to see if things are making sense:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print X_train.shape\n",
      "print X_test.shape\n",
      "print y_train.shape\n",
      "print y_test.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(7500, 3072)\n",
        "(2500, 3072)\n",
        "(7500,)\n",
        "(2500,)\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y = np.bincount(y_train)\n",
      "ii = np.nonzero(y)[0]      # gets indices of y\n",
      "print zip(ii,y[ii])\n",
      "print y"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[(0, 754), (1, 740), (2, 784), (3, 762), (4, 765), (5, 709), (6, 753), (7, 756), (8, 749), (9, 728)]\n",
        "[754 740 784 762 765 709 753 756 749 728]\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Define a function to evaluate K-fold cross-validation:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import cross_val_score, KFold\n",
      "from scipy.stats import sem"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def evaluate_cross_validation(clf, X, y, K):\n",
      "    #create a k-fold cross validation iterator\n",
      "    cv = KFold(len(y), K, shuffle=True, random_state=0)\n",
      "    # by default, the score used is the one returned by score method of estimator (`accuracy`)\n",
      "    scores = cross_val_score(clf, X, y, cv=cv)\n",
      "    print scores\n",
      "    print(\"Mean score: {0:.3f} (+/- {1:.3f})\").format(np.mean(scores),sem(scores))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "evaluate_cross_validation(svc_1, X_train, y_train, 5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 0.294       0.318       0.30466667  0.3         0.3       ]\n",
        "Mean score: 0.303 (+/- 0.004)\n"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "evaluate_cross_validation(rbf_svc, X_train, y_train, 3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 0.1032  0.1032  0.0984]\n",
        "Mean score: 0.102 (+/- 0.002)\n"
       ]
      }
     ],
     "prompt_number": 33
    }
   ],
   "metadata": {}
  }
 ]
}